// Copyright (c) Zefchain Labs, Inc.
// SPDX-License-Identifier: Apache-2.0

use crate::{
    batch::{Batch, DeletePrefixExpander, SimpleUnorderedBatch},
    common::{
        CommonStoreConfig, ContextFromDb, KeyIterable, KeyValueIterable, KeyValueStoreClient,
        TableStatus, MIN_VIEW_TAG,
    },
    localstack,
    lru_caching::LruCachingKeyValueClient,
    value_splitting::{DatabaseConsistencyError, ValueSplittingKeyValueStoreClient},
};
use async_lock::{Semaphore, SemaphoreGuard};
use async_trait::async_trait;
use aws_sdk_dynamodb::{
    error::GetItemErrorKind,
    model::{
        AttributeDefinition, AttributeValue, Delete, KeySchemaElement, KeyType,
        ProvisionedThroughput, Put, ScalarAttributeType, TransactWriteItem,
    },
    output::QueryOutput,
    types::{Blob, SdkError},
    Client,
};
use futures::future::join_all;
use serde::{Deserialize, Serialize};
use static_assertions as sa;
use std::{collections::HashMap, mem, str::FromStr, sync::Arc};
use thiserror::Error;

#[cfg(any(test, feature = "test"))]
use {
    crate::common::get_table_name,
    crate::lru_caching::TEST_CACHE_SIZE,
    anyhow::{Context, Error},
    aws_sdk_s3::Endpoint,
    aws_types::SdkConfig,
    std::env,
    tokio::sync::{Mutex, MutexGuard},
};

/// The configuration to connect to DynamoDB.
pub type Config = aws_sdk_dynamodb::Config;

#[cfg(test)]
#[path = "unit_tests/dynamo_db_context_tests.rs"]
mod dynamo_db_context_tests;

/// The tag used for the journal stuff.
const JOURNAL_TAG: u8 = 0;
sa::const_assert!(JOURNAL_TAG < MIN_VIEW_TAG);

/// The attribute name of the partition key.
const PARTITION_ATTRIBUTE: &str = "item_partition";

/// A dummy value to use as the partition key.
const DUMMY_PARTITION_KEY: &[u8] = &[0];

/// A key being used for testing existence of tables
const DB_KEY: &[u8] = &[0];

/// The attribute name of the primary key (used as a sort key).
const KEY_ATTRIBUTE: &str = "item_key";

/// The attribute name of the table value blob.
const VALUE_ATTRIBUTE: &str = "item_value";

/// The attribute for obtaining the primary key (used as a sort key) with the stored value.
const KEY_VALUE_ATTRIBUTE: &str = "item_key, item_value";

/// Fundamental constants in DynamoDB: The maximum size of a value is 400KB
/// See https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ServiceQuotas.html
const MAX_VALUE_BYTES: usize = 409600;

/// Fundamental constants in DynamoDB: The maximum size of a TransactWriteItem is 4M.
/// See https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_TransactWriteItems.html
const _MAX_TRANSACT_WRITE_ITEM_BYTES: usize = 4194304;

/// The DynamoDb database is potentially handling an infinite number of connections.
/// However, for testing or some other purpose we really need to decrease the number of
/// connections.
pub const TEST_DYNAMO_DB_MAX_CONCURRENT_QUERIES: usize = 10;

/// The number of entries in a stream of the tests can be controlled by this parameter for tests.
pub const TEST_DYNAMO_DB_MAX_STREAM_QUERIES: usize = 10;

/// Fundamental constants in DynamoDB: The maximum size of a TransactWriteItem is 100.
/// See <https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_TransactWriteItems.html>
pub const MAX_TRANSACT_WRITE_ITEM_SIZE: usize = 100;

/// Fundamental constants in DynamoDB: The maximum size of a BatchWriteItem is 16M.
/// See <https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_BatchWriteItem.html>
const MAX_BATCH_WRITE_ITEM_BYTES: usize = 16777216;

/// This limit guarantees that the values seen by DynamoDb are under 400 kB = 409600 bytes.
const MAX_VALUE_SIZE: usize = 409000;

/// Builds the key attributes for a table item.
///
/// The key is composed of two attributes that are both binary blobs. The first attribute is a
/// partition key and is currently just a dummy value that ensures all items are in the same
/// partion. This is necessary for range queries to work correctly.
///
/// The second attribute is the actual key value, which is generated by concatenating the
/// context prefix. The Vec<u8> expression is obtained from self.derive_key.
fn build_key(key: Vec<u8>) -> HashMap<String, AttributeValue> {
    [
        (
            PARTITION_ATTRIBUTE.to_owned(),
            AttributeValue::B(Blob::new(DUMMY_PARTITION_KEY)),
        ),
        (KEY_ATTRIBUTE.to_owned(), AttributeValue::B(Blob::new(key))),
    ]
    .into()
}

/// Builds the value attribute for storing a table item.
fn build_key_value(key: Vec<u8>, value: Vec<u8>) -> HashMap<String, AttributeValue> {
    [
        (
            PARTITION_ATTRIBUTE.to_owned(),
            AttributeValue::B(Blob::new(DUMMY_PARTITION_KEY)),
        ),
        (KEY_ATTRIBUTE.to_owned(), AttributeValue::B(Blob::new(key))),
        (
            VALUE_ATTRIBUTE.to_owned(),
            AttributeValue::B(Blob::new(value)),
        ),
    ]
    .into()
}

/// Extracts the key attribute from an item.
fn extract_key(
    prefix_len: usize,
    attributes: &HashMap<String, AttributeValue>,
) -> Result<&[u8], DynamoDbContextError> {
    let key = attributes
        .get(KEY_ATTRIBUTE)
        .ok_or(DynamoDbContextError::MissingKey)?;
    match key {
        AttributeValue::B(blob) => Ok(&blob.as_ref()[prefix_len..]),
        key => Err(DynamoDbContextError::wrong_key_type(key)),
    }
}

/// Extracts the value attribute from an item.
fn extract_value(
    attributes: &HashMap<String, AttributeValue>,
) -> Result<&[u8], DynamoDbContextError> {
    // According to the official AWS DynamoDB documentation:
    // "Binary must have a length greater than zero if the attribute is used as a key attribute for a table or index"
    let value = attributes
        .get(VALUE_ATTRIBUTE)
        .ok_or(DynamoDbContextError::MissingValue)?;
    match value {
        AttributeValue::B(blob) => Ok(blob.as_ref()),
        value => Err(DynamoDbContextError::wrong_value_type(value)),
    }
}

/// Extracts the value attribute from an item (returned by value).
fn extract_value_owned(
    attributes: &mut HashMap<String, AttributeValue>,
) -> Result<Vec<u8>, DynamoDbContextError> {
    let value = attributes
        .remove(VALUE_ATTRIBUTE)
        .ok_or(DynamoDbContextError::MissingValue)?;
    match value {
        AttributeValue::B(blob) => Ok(blob.into_inner()),
        value => Err(DynamoDbContextError::wrong_value_type(&value)),
    }
}

/// Extracts the key and value attributes from an item.
fn extract_key_value(
    prefix_len: usize,
    attributes: &HashMap<String, AttributeValue>,
) -> Result<(&[u8], &[u8]), DynamoDbContextError> {
    let key = extract_key(prefix_len, attributes)?;
    let value = extract_value(attributes)?;
    Ok((key, value))
}

/// Extracts the `(key, value)` pair attributes from an item (returned by value).
fn extract_key_value_owned(
    prefix_len: usize,
    attributes: &mut HashMap<String, AttributeValue>,
) -> Result<(Vec<u8>, Vec<u8>), DynamoDbContextError> {
    let key = extract_key(prefix_len, attributes)?.to_vec();
    let value = extract_value_owned(attributes)?;
    Ok((key, value))
}

#[derive(Default)]
struct TransactionBuilder {
    transacts: Vec<TransactWriteItem>,
}

impl TransactionBuilder {
    fn insert_delete_request(
        &mut self,
        key: Vec<u8>,
        db: &DynamoDbClientInternal,
    ) -> Result<(), DynamoDbContextError> {
        if key.is_empty() {
            return Err(DynamoDbContextError::ZeroLengthKey);
        }
        let request = Delete::builder()
            .table_name(&db.table.0)
            .set_key(Some(build_key(key)))
            .build();
        let transact = TransactWriteItem::builder().delete(request).build();
        self.transacts.push(transact);
        Ok(())
    }

    fn insert_put_request(
        &mut self,
        key: Vec<u8>,
        value: Vec<u8>,
        db: &DynamoDbClientInternal,
    ) -> Result<(), DynamoDbContextError> {
        if key.is_empty() {
            return Err(DynamoDbContextError::ZeroLengthKey);
        }
        if value.len() > MAX_VALUE_BYTES {
            return Err(DynamoDbContextError::ValueLengthTooLarge);
        }
        let request = Put::builder()
            .table_name(&db.table.0)
            .set_item(Some(build_key_value(key, value)))
            .build();
        let transact = TransactWriteItem::builder().put(request).build();
        self.transacts.push(transact);
        Ok(())
    }

    async fn submit(self, db: &DynamoDbClientInternal) -> Result<(), DynamoDbContextError> {
        if self.transacts.len() > MAX_TRANSACT_WRITE_ITEM_SIZE {
            return Err(DynamoDbContextError::TransactUpperLimitSize);
        }
        if !self.transacts.is_empty() {
            let _guard = db.acquire().await;
            db.client
                .transact_write_items()
                .set_transact_items(Some(self.transacts))
                .send()
                .await?;
        }
        // Drop the output of type TransactWriteItemsOutput
        Ok(())
    }
}

#[repr(u8)]
enum KeyTag {
    /// Prefix for the storing of the header of the journal.
    Journal = 1,
    /// Prefix for the block entry.
    Entry,
}

fn get_journaling_key(base_key: &[u8], tag: u8, pos: u32) -> Result<Vec<u8>, DynamoDbContextError> {
    // We used the value 0 because it does not collide with other key values.
    // since other tags are starting from 1.
    let mut key = base_key.to_vec();
    key.extend([JOURNAL_TAG]);
    key.extend([tag]);
    bcs::serialize_into(&mut key, &pos)?;
    Ok(key)
}

/// The header that contains the current state of the journal.
#[derive(Serialize, Deserialize)]
struct JournalHeader {
    block_count: u32,
}

impl JournalHeader {
    /// Resolves the database by using the header that has been retrieved
    async fn coherently_resolve_journal(
        mut self,
        db: &DynamoDbClientInternal,
        base_key: &[u8],
    ) -> Result<(), DynamoDbContextError> {
        loop {
            if self.block_count == 0 {
                break;
            }
            let key = get_journaling_key(base_key, KeyTag::Entry as u8, self.block_count - 1)?;
            let value = db.read_key::<DynamoDbBatch>(&key).await?;
            if let Some(value) = value {
                let mut tb = TransactionBuilder::default();
                tb.insert_delete_request(key, db)?; // Delete the preceding journal entry
                for delete in value.0.deletions {
                    tb.insert_delete_request(delete, db)?;
                }
                for key_value in value.0.insertions {
                    tb.insert_put_request(key_value.0, key_value.1, db)?;
                }
                self.block_count -= 1;
                DynamoDbBatch::add_journal_header_operations(&mut tb, &self, db, base_key)?;
                tb.submit(db).await?;
            } else {
                return Err(DynamoDbContextError::DatabaseRecoveryFailed);
            }
        }
        Ok(())
    }
}

/// The bunch of deletes and writes to be done.
#[derive(Serialize, Deserialize)]
struct DynamoDbBatch(SimpleUnorderedBatch);

impl DynamoDbBatch {
    /// The total number of entries to be submitted
    fn len(&self) -> usize {
        self.0.deletions.len() + self.0.insertions.len()
    }

    fn is_fastpath_feasible(&self) -> bool {
        self.len() <= MAX_TRANSACT_WRITE_ITEM_SIZE
    }

    fn add_journal_header_operations(
        transact_builder: &mut TransactionBuilder,
        header: &JournalHeader,
        db: &DynamoDbClientInternal,
        base_key: &[u8],
    ) -> Result<(), DynamoDbContextError> {
        let key = get_journaling_key(base_key, KeyTag::Journal as u8, 0)?;
        if header.block_count > 0 {
            let value = bcs::to_bytes(header)?;
            transact_builder.insert_put_request(key, value, db)?;
        } else {
            transact_builder.insert_delete_request(key, db)?;
        }
        Ok(())
    }

    /// Writes blocks to the database and resolves them later.
    pub async fn write_journal(
        self,
        db: &DynamoDbClientInternal,
        base_key: &[u8],
    ) -> Result<JournalHeader, DynamoDbContextError> {
        let delete_count = self.0.deletions.len();
        let insert_count = self.0.insertions.len();
        let total_count = delete_count + insert_count;
        let mut curr_size = 0;
        let mut curr_len = 0;
        let mut deletions = Vec::new();
        let mut insertions = Vec::new();
        let mut block_count = 0;
        for i in 0..total_count {
            curr_len += 1;
            if i < delete_count {
                let delete = &self.0.deletions[i];
                curr_size += delete.len();
                deletions.push(delete.to_vec());
            } else {
                let key_value = &self.0.insertions[i - delete_count];
                curr_size += key_value.0.len() + key_value.1.len();
                insertions.push(key_value.clone());
            }
            let do_flush = if i == total_count - 1 || curr_len == MAX_TRANSACT_WRITE_ITEM_SIZE - 2 {
                true
            } else {
                let size_next = if i + 1 < delete_count {
                    self.0.deletions[i + 1].len()
                } else {
                    let key_value = &self.0.insertions[i + 1 - delete_count];
                    key_value.0.len() + key_value.1.len()
                };
                curr_size + size_next > MAX_BATCH_WRITE_ITEM_BYTES
            };
            if do_flush {
                let simple_unordered_batch = SimpleUnorderedBatch {
                    deletions: mem::take(&mut deletions),
                    insertions: mem::take(&mut insertions),
                };
                let entry = DynamoDbBatch(simple_unordered_batch);
                let key = get_journaling_key(base_key, KeyTag::Entry as u8, block_count)?;
                let value = bcs::to_bytes(&entry)?;
                db.write_single_key_value(key, value).await?;
                block_count += 1;
                curr_size = 0;
                curr_len = 0;
            }
        }
        let header = JournalHeader { block_count };
        if block_count > 0 {
            let key = get_journaling_key(base_key, KeyTag::Journal as u8, 0)?;
            let value = bcs::to_bytes(&header)?;
            db.write_single_key_value(key, value).await?;
        }
        Ok(header)
    }

    /// This code is for submitting the transaction in one single transaction when that is possible.
    pub async fn write_fastpath_failsafe(
        self,
        db: &DynamoDbClientInternal,
    ) -> Result<(), DynamoDbContextError> {
        let mut tb = TransactionBuilder::default();
        for key in self.0.deletions {
            tb.insert_delete_request(key, db)?;
        }
        for key_value in self.0.insertions {
            tb.insert_put_request(key_value.0, key_value.1, db)?;
        }
        tb.submit(db).await
    }

    async fn from_batch(
        db: &DynamoDbClientInternal,
        batch: Batch,
    ) -> Result<Self, DynamoDbContextError> {
        // The DynamoDB does not support the `DeletePrefix` operation.
        // Therefore it does not make sense to have a delete prefix and they have to
        // be downloaded for making a list.
        // Also we remove the deletes that are followed by inserts on the same key because
        // the TransactWriteItem and BatchWriteItem are not going to work that way.
        let unordered_batch = batch.simplify();
        let simple_unordered_batch = unordered_batch.expand_delete_prefixes(db).await?;
        Ok(DynamoDbBatch(simple_unordered_batch))
    }
}

// Inspired by https://depth-first.com/articles/2020/06/22/returning-rust-iterators/
#[doc(hidden)]
pub struct DynamoDbKeyIterator<'a> {
    prefix_len: usize,
    iter: std::iter::Flatten<
        std::option::Iter<'a, Vec<HashMap<std::string::String, AttributeValue>>>,
    >,
}

impl<'a> Iterator for DynamoDbKeyIterator<'a> {
    type Item = Result<&'a [u8], DynamoDbContextError>;

    fn next(&mut self) -> Option<Self::Item> {
        self.iter.next().map(|x| extract_key(self.prefix_len, x))
    }
}

/// A set of keys returned by a search query on DynamoDB.
pub struct DynamoDbKeys {
    prefix_len: usize,
    response: Box<QueryOutput>,
}

impl KeyIterable<DynamoDbContextError> for DynamoDbKeys {
    type Iterator<'a> = DynamoDbKeyIterator<'a> where Self: 'a;

    fn iterator(&self) -> Self::Iterator<'_> {
        DynamoDbKeyIterator {
            prefix_len: self.prefix_len,
            iter: self.response.items.iter().flatten(),
        }
    }
}

// Inspired by https://depth-first.com/articles/2020/06/22/returning-rust-iterators/
#[doc(hidden)]
pub struct DynamoDbKeyValueIterator<'a> {
    prefix_len: usize,
    iter: std::iter::Flatten<
        std::option::Iter<'a, Vec<HashMap<std::string::String, AttributeValue>>>,
    >,
}

impl<'a> Iterator for DynamoDbKeyValueIterator<'a> {
    type Item = Result<(&'a [u8], &'a [u8]), DynamoDbContextError>;

    fn next(&mut self) -> Option<Self::Item> {
        self.iter
            .next()
            .map(|x| extract_key_value(self.prefix_len, x))
    }
}

#[doc(hidden)]
pub struct DynamoDbKeyValueIteratorOwned {
    prefix_len: usize,
    iter: std::iter::Flatten<
        std::option::IntoIter<Vec<HashMap<std::string::String, AttributeValue>>>,
    >,
}

impl Iterator for DynamoDbKeyValueIteratorOwned {
    type Item = Result<(Vec<u8>, Vec<u8>), DynamoDbContextError>;

    fn next(&mut self) -> Option<Self::Item> {
        self.iter
            .next()
            .map(|mut x| extract_key_value_owned(self.prefix_len, &mut x))
    }
}

/// A set of `(key, value)` returned by a search query on DynamoDb.
pub struct DynamoDbKeyValues {
    prefix_len: usize,
    response: Box<QueryOutput>,
}

impl KeyValueIterable<DynamoDbContextError> for DynamoDbKeyValues {
    type Iterator<'a> = DynamoDbKeyValueIterator<'a> where Self: 'a;
    type IteratorOwned = DynamoDbKeyValueIteratorOwned;

    fn iterator(&self) -> Self::Iterator<'_> {
        DynamoDbKeyValueIterator {
            prefix_len: self.prefix_len,
            iter: self.response.items.iter().flatten(),
        }
    }

    fn into_iterator_owned(self) -> Self::IteratorOwned {
        DynamoDbKeyValueIteratorOwned {
            prefix_len: self.prefix_len,
            iter: self.response.items.into_iter().flatten(),
        }
    }
}

/// A DynamoDB client.
#[derive(Debug, Clone)]
pub struct DynamoDbClientInternal {
    client: Client,
    table: TableName,
    semaphore: Option<Arc<Semaphore>>,
    max_stream_queries: usize,
}

#[async_trait]
impl DeletePrefixExpander for DynamoDbClientInternal {
    type Error = DynamoDbContextError;
    async fn expand_delete_prefix(&self, key_prefix: &[u8]) -> Result<Vec<Vec<u8>>, Self::Error> {
        let mut vector_list = Vec::new();
        for key in self.find_keys_by_prefix(key_prefix).await?.iterator() {
            vector_list.push(key?.to_vec());
        }
        Ok(vector_list)
    }
}

impl DynamoDbClientInternal {
    /// Obtains the semaphore lock on the database if needed.
    async fn acquire(&self) -> Option<SemaphoreGuard<'_>> {
        match &self.semaphore {
            None => None,
            Some(count) => Some(count.acquire().await),
        }
    }

    /// Testing the existence of a table
    pub async fn test_table_existence(
        client: &Client,
        table: &TableName,
    ) -> Result<bool, DynamoDbContextError> {
        let key_db = build_key(DB_KEY.to_vec());
        let response = client
            .get_item()
            .table_name(table.as_ref())
            .set_key(Some(key_db))
            .send()
            .await;
        let Err(error) = response else {
            return Ok(true);
        };
        let test = match &error {
            SdkError::ServiceError { err, raw: _ } => match &err.kind {
                GetItemErrorKind::ResourceNotFoundException(inner_error) => {
                    inner_error.message
                        == Some("Cannot do operations on a non-existent table".to_string())
                }
                _ => false,
            },
            _ => false,
        };
        if test {
            Ok(false)
        } else {
            Err(error.into())
        }
    }

    /// Creates a new [`DynamoDbClientInternal`] instance from scratch using the provided `config` parameters.
    #[cfg(any(test, feature = "test"))]
    pub async fn new_for_testing(
        store_config: DynamoDbKvStoreConfig,
    ) -> Result<(Self, TableStatus), DynamoDbContextError> {
        let client = Client::from_conf(store_config.config);
        if Self::test_table_existence(&client, &store_config.table_name).await? {
            client
                .delete_table()
                .table_name(&store_config.table_name.0)
                .send()
                .await?;
        }
        let stop_if_table_exists = true;
        let create_if_missing = true;
        Self::new_internal(
            client,
            store_config.table_name,
            store_config.common_config,
            stop_if_table_exists,
            create_if_missing,
        )
        .await
    }

    /// Testing the existence of a table
    pub async fn test_existence(
        store_config: DynamoDbKvStoreConfig,
    ) -> Result<bool, DynamoDbContextError> {
        let client = Client::from_conf(store_config.config);
        Self::test_table_existence(&client, &store_config.table_name).await
    }

    async fn delete_all(store_config: DynamoDbKvStoreConfig) -> Result<(), DynamoDbContextError> {
        let client = Client::from_conf(store_config.config);
        clear_tables(&client).await?;
        Ok(())
    }

    async fn delete_single(
        store_config: DynamoDbKvStoreConfig,
    ) -> Result<(), DynamoDbContextError> {
        let client = Client::from_conf(store_config.config);
        client
            .delete_table()
            .table_name(&store_config.table_name.0)
            .send()
            .await?;
        Ok(())
    }

    /// Creates a new [`DynamoDbClientInternal`] instance using the provided `config` parameters.
    pub async fn new(
        store_config: DynamoDbKvStoreConfig,
    ) -> Result<(Self, TableStatus), DynamoDbContextError> {
        let client = Client::from_conf(store_config.config);
        let stop_if_table_exists = false;
        let create_if_missing = false;
        Self::new_internal(
            client,
            store_config.table_name,
            store_config.common_config,
            stop_if_table_exists,
            create_if_missing,
        )
        .await
    }

    /// Initializes a RocksDB database from a specified path.
    pub async fn initialize(
        store_config: DynamoDbKvStoreConfig,
    ) -> Result<Self, DynamoDbContextError> {
        let client = Client::from_conf(store_config.config);
        let stop_if_table_exists = false;
        let create_if_missing = true;
        let (client, table_status) = Self::new_internal(
            client,
            store_config.table_name,
            store_config.common_config,
            stop_if_table_exists,
            create_if_missing,
        )
        .await?;
        if table_status == TableStatus::Existing {
            return Err(DynamoDbContextError::AlreadyExistingDatabase);
        }
        Ok(client)
    }

    /// Creates a new [`DynamoDbClientInternal`] instance using the provided `config` parameters.
    async fn new_internal(
        client: Client,
        table: TableName,
        common_config: CommonStoreConfig,
        stop_if_table_exists: bool,
        create_if_missing: bool,
    ) -> Result<(Self, TableStatus), DynamoDbContextError> {
        let kv_name = format!("table={:?} common_config={:?}", table, common_config);
        let mut existing_table = Self::test_table_existence(&client, &table).await?;
        let semaphore = common_config
            .max_concurrent_queries
            .map(|n| Arc::new(Semaphore::new(n)));
        let max_stream_queries = common_config.max_stream_queries;
        let db = Self {
            client,
            table,
            semaphore,
            max_stream_queries,
        };
        if !existing_table {
            if create_if_missing {
                existing_table = db.create_table(stop_if_table_exists).await?;
            } else {
                tracing::info!("DynamoDb: Missing database for kv_name={}", kv_name);
                return Err(DynamoDbContextError::MissingDatabase(kv_name));
            }
        }
        let table_status = if existing_table {
            TableStatus::Existing
        } else {
            TableStatus::New
        };
        Ok((db, table_status))
    }

    async fn get_query_output(
        &self,
        attribute_str: &str,
        key_prefix: &[u8],
    ) -> Result<QueryOutput, DynamoDbContextError> {
        let _guard = self.acquire().await;
        let response = self
            .client
            .query()
            .table_name(self.table.as_ref())
            .projection_expression(attribute_str)
            .key_condition_expression(format!(
                "{PARTITION_ATTRIBUTE} = :partition and begins_with({KEY_ATTRIBUTE}, :prefix)"
            ))
            .expression_attribute_values(
                ":partition",
                AttributeValue::B(Blob::new(DUMMY_PARTITION_KEY)),
            )
            .expression_attribute_values(":prefix", AttributeValue::B(Blob::new(key_prefix)))
            .send()
            .await?;
        Ok(response)
    }

    async fn read_key_bytes_general(
        &self,
        key_db: HashMap<String, AttributeValue>,
    ) -> Result<Option<Vec<u8>>, DynamoDbContextError> {
        let _guard = self.acquire().await;
        let response = self
            .client
            .get_item()
            .table_name(self.table.as_ref())
            .set_key(Some(key_db))
            .send()
            .await?;

        match response.item {
            Some(mut item) => {
                let value = extract_value_owned(&mut item)?;
                Ok(Some(value))
            }
            None => Ok(None),
        }
    }

    async fn write_single_key_value(
        &self,
        key: Vec<u8>,
        value: Vec<u8>,
    ) -> Result<(), DynamoDbContextError> {
        let mut tb = TransactionBuilder::default();
        tb.insert_put_request(key, value, self)?;
        tb.submit(self).await
    }

    /// Creates the table. Returns whether there was already a table.
    /// If `stop_if_exists` is true then an already present table raises an error.
    ///
    /// We need that because the `test_table_existence` might return `false`
    /// from several processes but only one creates it.
    async fn create_table(&self, stop_if_table_exists: bool) -> Result<bool, DynamoDbContextError> {
        let _guard = self.acquire().await;
        let result = self
            .client
            .create_table()
            .table_name(self.table.as_ref())
            .attribute_definitions(
                AttributeDefinition::builder()
                    .attribute_name(PARTITION_ATTRIBUTE)
                    .attribute_type(ScalarAttributeType::B)
                    .build(),
            )
            .attribute_definitions(
                AttributeDefinition::builder()
                    .attribute_name(KEY_ATTRIBUTE)
                    .attribute_type(ScalarAttributeType::B)
                    .build(),
            )
            .key_schema(
                KeySchemaElement::builder()
                    .attribute_name(PARTITION_ATTRIBUTE)
                    .key_type(KeyType::Hash)
                    .build(),
            )
            .key_schema(
                KeySchemaElement::builder()
                    .attribute_name(KEY_ATTRIBUTE)
                    .key_type(KeyType::Range)
                    .build(),
            )
            .provisioned_throughput(
                ProvisionedThroughput::builder()
                    .read_capacity_units(10)
                    .write_capacity_units(10)
                    .build(),
            )
            .send()
            .await;
        let Err(error) = result else {
            return Ok(false);
        };
        if stop_if_table_exists {
            return Err(error.into());
        }
        if error.is_resource_in_use_exception() {
            Ok(true)
        } else {
            Err(error.into())
        }
    }
}

#[async_trait]
impl KeyValueStoreClient for DynamoDbClientInternal {
    const MAX_VALUE_SIZE: usize = MAX_VALUE_SIZE;
    type Error = DynamoDbContextError;
    type Keys = DynamoDbKeys;
    type KeyValues = DynamoDbKeyValues;

    fn max_stream_queries(&self) -> usize {
        self.max_stream_queries
    }

    async fn read_key_bytes(&self, key: &[u8]) -> Result<Option<Vec<u8>>, DynamoDbContextError> {
        let key_db = build_key(key.to_vec());
        self.read_key_bytes_general(key_db).await
    }

    async fn read_multi_key_bytes(
        &self,
        keys: Vec<Vec<u8>>,
    ) -> Result<Vec<Option<Vec<u8>>>, DynamoDbContextError> {
        let mut handles = Vec::new();
        for key in keys {
            let key_db = build_key(key);
            let handle = self.read_key_bytes_general(key_db);
            handles.push(handle);
        }
        let result = join_all(handles).await;
        Ok(result.into_iter().collect::<Result<_, _>>()?)
    }

    // TODO(#201): Large responses may be truncated.
    async fn find_keys_by_prefix(
        &self,
        key_prefix: &[u8],
    ) -> Result<DynamoDbKeys, DynamoDbContextError> {
        if key_prefix.is_empty() {
            return Err(DynamoDbContextError::ZeroLengthKeyPrefix);
        }
        let response = Box::new(self.get_query_output(KEY_ATTRIBUTE, key_prefix).await?);
        Ok(DynamoDbKeys {
            prefix_len: key_prefix.len(),
            response,
        })
    }

    // TODO(#201): Large responses may be truncated.
    async fn find_key_values_by_prefix(
        &self,
        key_prefix: &[u8],
    ) -> Result<DynamoDbKeyValues, DynamoDbContextError> {
        if key_prefix.is_empty() {
            return Err(DynamoDbContextError::ZeroLengthKeyPrefix);
        }
        let response = Box::new(
            self.get_query_output(KEY_VALUE_ATTRIBUTE, key_prefix)
                .await?,
        );
        Ok(DynamoDbKeyValues {
            prefix_len: key_prefix.len(),
            response,
        })
    }

    async fn write_batch(&self, batch: Batch, base_key: &[u8]) -> Result<(), DynamoDbContextError> {
        let block_operations = DynamoDbBatch::from_batch(self, batch).await?;
        if block_operations.is_fastpath_feasible() {
            block_operations.write_fastpath_failsafe(self).await
        } else {
            let header = block_operations.write_journal(self, base_key).await?;
            header.coherently_resolve_journal(self, base_key).await
        }
    }

    async fn clear_journal(&self, base_key: &[u8]) -> Result<(), DynamoDbContextError> {
        let key = get_journaling_key(base_key, KeyTag::Journal as u8, 0)?;
        let value = self.read_key::<JournalHeader>(&key).await?;
        if let Some(header) = value {
            header.coherently_resolve_journal(self, base_key).await?;
        }
        Ok(())
    }
}

/// A shared DB client for DynamoDb implementing LruCaching
#[derive(Clone)]
pub struct DynamoDbClient {
    client: LruCachingKeyValueClient<ValueSplittingKeyValueStoreClient<DynamoDbClientInternal>>,
}

#[async_trait]
impl KeyValueStoreClient for DynamoDbClient {
    const MAX_VALUE_SIZE: usize = MAX_VALUE_SIZE;
    type Error = DynamoDbContextError;
    type Keys = Vec<Vec<u8>>;
    type KeyValues = Vec<(Vec<u8>, Vec<u8>)>;

    fn max_stream_queries(&self) -> usize {
        self.client.max_stream_queries()
    }

    async fn read_key_bytes(&self, key: &[u8]) -> Result<Option<Vec<u8>>, DynamoDbContextError> {
        self.client.read_key_bytes(key).await
    }

    async fn read_multi_key_bytes(
        &self,
        key: Vec<Vec<u8>>,
    ) -> Result<Vec<Option<Vec<u8>>>, DynamoDbContextError> {
        self.client.read_multi_key_bytes(key).await
    }

    async fn find_keys_by_prefix(
        &self,
        key_prefix: &[u8],
    ) -> Result<Self::Keys, DynamoDbContextError> {
        self.client.find_keys_by_prefix(key_prefix).await
    }

    async fn find_key_values_by_prefix(
        &self,
        key_prefix: &[u8],
    ) -> Result<Self::KeyValues, DynamoDbContextError> {
        self.client.find_key_values_by_prefix(key_prefix).await
    }

    async fn write_batch(&self, batch: Batch, base_key: &[u8]) -> Result<(), DynamoDbContextError> {
        self.client.write_batch(batch, base_key).await
    }

    async fn clear_journal(&self, base_key: &[u8]) -> Result<(), Self::Error> {
        self.client.clear_journal(base_key).await
    }
}

impl DynamoDbClient {
    /// Creates a `DynamoDbClient` from scratch with an LRU cache
    #[cfg(any(test, feature = "test"))]
    pub async fn new_for_testing(
        store_config: DynamoDbKvStoreConfig,
    ) -> Result<(Self, TableStatus), DynamoDbContextError> {
        let cache_size = store_config.common_config.cache_size;
        let (client, table_status) = DynamoDbClientInternal::new_for_testing(store_config).await?;
        let client = ValueSplittingKeyValueStoreClient::new(client);
        let client = Self {
            client: LruCachingKeyValueClient::new(client, cache_size),
        };
        Ok((client, table_status))
    }

    /// Initializes a `DynamoDbClient`.
    pub async fn initialize(
        store_config: DynamoDbKvStoreConfig,
    ) -> Result<Self, DynamoDbContextError> {
        let cache_size = store_config.common_config.cache_size;
        let client = DynamoDbClientInternal::initialize(store_config).await?;
        let client = ValueSplittingKeyValueStoreClient::new(client);
        let client = Self {
            client: LruCachingKeyValueClient::new(client, cache_size),
        };
        Ok(client)
    }

    /// Deletes all the tables from the database
    pub async fn test_existence(
        store_config: DynamoDbKvStoreConfig,
    ) -> Result<bool, DynamoDbContextError> {
        DynamoDbClientInternal::test_existence(store_config).await
    }

    /// Deletes all the tables from the database
    pub async fn delete_all(
        store_config: DynamoDbKvStoreConfig,
    ) -> Result<(), DynamoDbContextError> {
        DynamoDbClientInternal::delete_all(store_config).await
    }

    /// Deletes a single table from the database
    pub async fn delete_single(
        store_config: DynamoDbKvStoreConfig,
    ) -> Result<(), DynamoDbContextError> {
        DynamoDbClientInternal::delete_single(store_config).await
    }

    /// Creates a `DynamoDbClient` with an LRU cache
    pub async fn new(
        store_config: DynamoDbKvStoreConfig,
    ) -> Result<(Self, TableStatus), DynamoDbContextError> {
        let cache_size = store_config.common_config.cache_size;
        let (client, table_name) = DynamoDbClientInternal::new(store_config).await?;
        let client = ValueSplittingKeyValueStoreClient::new(client);
        let client = Self {
            client: LruCachingKeyValueClient::new(client, cache_size),
        };
        Ok((client, table_name))
    }
}

/// Gets the AWS configuration from the environment
pub async fn get_base_config() -> Result<Config, DynamoDbContextError> {
    let base_config = aws_config::load_from_env().await;
    Ok((&base_config).into())
}

/// Gets the localstack config
pub async fn get_localstack_config() -> Result<Config, DynamoDbContextError> {
    let base_config = aws_config::load_from_env().await;
    Ok(aws_sdk_dynamodb::config::Builder::from(&base_config)
        .endpoint_resolver(localstack::get_endpoint()?)
        .build())
}

/// Getting a configuration for the system
pub async fn get_config(use_localstack: bool) -> Result<Config, DynamoDbContextError> {
    if use_localstack {
        get_localstack_config().await
    } else {
        get_base_config().await
    }
}

/// The initial configuration of the system
#[derive(Debug)]
pub struct DynamoDbKvStoreConfig {
    /// The AWS configuration
    pub config: Config,
    /// The table_name used
    pub table_name: TableName,
    /// The common configuration of the key value store
    pub common_config: CommonStoreConfig,
}

/// An implementation of [`Context`][trait1] based on [`DynamoDbClient`].
///
/// [trait1]: crate::common::Context
pub type DynamoDbContext<E> = ContextFromDb<E, DynamoDbClient>;

impl<E> DynamoDbContext<E>
where
    E: Clone + Sync + Send,
{
    /// Creates a new [`DynamoDbContext`] instance from scratch from the given AWS configuration.
    #[cfg(any(test, feature = "test"))]
    pub async fn new_for_testing(
        store_config: DynamoDbKvStoreConfig,
        base_key: Vec<u8>,
        extra: E,
    ) -> Result<(Self, TableStatus), DynamoDbContextError> {
        let (db, table_status) = DynamoDbClient::new_for_testing(store_config).await?;
        let storage = DynamoDbContext {
            db,
            base_key,
            extra,
        };
        Ok((storage, table_status))
    }

    /// Creates a new [`DynamoDbContext`] instance from the given AWS configuration.
    pub async fn new(
        store_config: DynamoDbKvStoreConfig,
        base_key: Vec<u8>,
        extra: E,
    ) -> Result<(Self, TableStatus), DynamoDbContextError> {
        let (db, table_status) = DynamoDbClient::new(store_config).await?;
        let storage = DynamoDbContext {
            db,
            base_key,
            extra,
        };
        Ok((storage, table_status))
    }
}

/// A DynamoDB table name.
///
/// Table names must follow some [naming
/// rules](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.NamingRulesDataTypes.html#HowItWorks.NamingRules),
/// so this type ensures that they are properly validated.
#[derive(Clone, Debug, Eq, PartialEq)]
pub struct TableName(String);

impl FromStr for TableName {
    type Err = InvalidTableName;

    fn from_str(string: &str) -> Result<Self, Self::Err> {
        if string.len() < 3 {
            return Err(InvalidTableName::TooShort);
        }
        if string.len() > 255 {
            return Err(InvalidTableName::TooLong);
        }
        if !string.chars().all(|character| {
            character.is_ascii_alphanumeric()
                || character == '.'
                || character == '-'
                || character == '_'
        }) {
            return Err(InvalidTableName::InvalidCharacter);
        }
        Ok(TableName(string.to_owned()))
    }
}

impl AsRef<String> for TableName {
    fn as_ref(&self) -> &String {
        &self.0
    }
}

/// Error when validating a table name.
#[derive(Debug, Error)]
pub enum InvalidTableName {
    /// The table name should be at least 3 characters.
    #[error("Table name must have at least 3 characters")]
    TooShort,

    /// The table name should be at most 63 characters.
    #[error("Table name must be at most 63 characters")]
    TooLong,

    /// allowed characters are lowercase letters, numbers, periods and hyphens
    #[error("Table name must only contain lowercase letters, numbers, periods and hyphens")]
    InvalidCharacter,
}

/// Errors that occur when using [`DynamoDbContext`].
#[derive(Debug, Error)]
pub enum DynamoDbContextError {
    /// An error occurred while getting the item.
    #[error(transparent)]
    Get(#[from] Box<SdkError<aws_sdk_dynamodb::error::GetItemError>>),

    /// An error occurred while writing a batch of items.
    #[error(transparent)]
    BatchWriteItem(#[from] Box<SdkError<aws_sdk_dynamodb::error::BatchWriteItemError>>),

    /// An error occurred while writing a transaction of items.
    #[error(transparent)]
    TransactWriteItem(#[from] Box<SdkError<aws_sdk_dynamodb::error::TransactWriteItemsError>>),

    /// An error occurred while doing a Query.
    #[error(transparent)]
    Query(#[from] Box<SdkError<aws_sdk_dynamodb::error::QueryError>>),

    /// An error occurred while deleting a table
    #[error(transparent)]
    DeleteTable(#[from] Box<SdkError<aws_sdk_dynamodb::error::DeleteTableError>>),

    /// An error occurred while listing tables
    #[error(transparent)]
    ListTables(#[from] Box<SdkError<aws_sdk_dynamodb::error::ListTablesError>>),

    /// The transact maximum size is MAX_TRANSACT_WRITE_ITEM_SIZE.
    #[error("The transact must have length at most MAX_TRANSACT_WRITE_ITEM_SIZE")]
    TransactUpperLimitSize,

    /// Keys have to be of non-zero length.
    #[error("The key must be of strictly positive length")]
    ZeroLengthKey,

    /// Key prefixes have to be of non-zero length.
    #[error("The key_prefix must be of strictly positive length")]
    ZeroLengthKeyPrefix,

    /// The recovery failed.
    #[error("The DynamoDB database recovery failed")]
    DatabaseRecoveryFailed,

    /// The database is not coherent
    #[error(transparent)]
    DatabaseConsistencyError(#[from] DatabaseConsistencyError),

    /// Missing database
    #[error("Missing database")]
    MissingDatabase(String),

    /// Already existing database
    #[error("Already existing database")]
    AlreadyExistingDatabase,

    /// The length of the value should be at most 400KB.
    #[error("The DynamoDB value should be less than 400KB")]
    ValueLengthTooLarge,

    /// The stored key is missing.
    #[error("The stored key attribute is missing")]
    MissingKey,

    /// The type of the keys was not correct (It should have been a binary blob).
    #[error("Key was stored as {0}, but it was expected to be stored as a binary blob")]
    WrongKeyType(String),

    /// The value attribute is missing.
    #[error("The stored value attribute is missing")]
    MissingValue,

    /// The value was stored as the wrong type (it should be a binary blob).
    #[error("Value was stored as {0}, but it was expected to be stored as a binary blob")]
    WrongValueType(String),

    /// A BCS error occurred.
    #[error(transparent)]
    BcsError(#[from] bcs::Error),

    /// An Endpoint error occurred.
    #[error(transparent)]
    Endpoint(#[from] localstack::EndpointError),

    /// An error occurred while creating the table.
    #[error(transparent)]
    CreateTable(#[from] SdkError<aws_sdk_dynamodb::error::CreateTableError>),
}

impl<InnerError> From<SdkError<InnerError>> for DynamoDbContextError
where
    DynamoDbContextError: From<Box<SdkError<InnerError>>>,
{
    fn from(error: SdkError<InnerError>) -> Self {
        Box::new(error).into()
    }
}

impl DynamoDbContextError {
    /// Creates a [`DynamoDbContextError::WrongKeyType`] instance based on the returned value type.
    ///
    /// # Panics
    ///
    /// If the value type is in the correct type, a binary blob.
    pub fn wrong_key_type(value: &AttributeValue) -> Self {
        DynamoDbContextError::WrongKeyType(Self::type_description_of(value))
    }

    /// Creates a [`DynamoDbContextError::WrongValueType`] instance based on the returned value type.
    ///
    /// # Panics
    ///
    /// If the value type is in the correct type, a binary blob.
    pub fn wrong_value_type(value: &AttributeValue) -> Self {
        DynamoDbContextError::WrongValueType(Self::type_description_of(value))
    }

    fn type_description_of(value: &AttributeValue) -> String {
        match value {
            AttributeValue::B(_) => unreachable!("creating an error type for the correct type"),
            AttributeValue::Bool(_) => "a boolean",
            AttributeValue::Bs(_) => "a list of binary blobs",
            AttributeValue::L(_) => "a list",
            AttributeValue::M(_) => "a map",
            AttributeValue::N(_) => "a number",
            AttributeValue::Ns(_) => "a list of numbers",
            AttributeValue::Null(_) => "a null value",
            AttributeValue::S(_) => "a string",
            AttributeValue::Ss(_) => "a list of strings",
            _ => "an unknown type",
        }
        .to_owned()
    }
}

impl From<DynamoDbContextError> for crate::views::ViewError {
    fn from(error: DynamoDbContextError) -> Self {
        Self::ContextError {
            backend: "DynamoDB".to_string(),
            error: error.to_string(),
        }
    }
}

/// A helper trait to add a `SdkError<CreateTableError>::is_resource_in_use_exception()` method.
trait IsResourceInUseException {
    /// Checks if the error is a resource is in use exception.
    fn is_resource_in_use_exception(&self) -> bool;
}

impl IsResourceInUseException for SdkError<aws_sdk_dynamodb::error::CreateTableError> {
    fn is_resource_in_use_exception(&self) -> bool {
        matches!(
            self,
            SdkError::ServiceError {
                err: aws_sdk_dynamodb::error::CreateTableError {
                    kind: aws_sdk_dynamodb::error::CreateTableErrorKind::ResourceInUseException(_),
                    ..
                },
                ..
            }
        )
    }
}

/// A static lock to prevent multiple tests from using the same LocalStack instance at the same
/// time.
#[cfg(any(test, feature = "test"))]
static LOCALSTACK_GUARD: Mutex<()> = Mutex::const_new(());

/// Name of the environment variable with the address to a LocalStack instance.
#[cfg(any(test, feature = "test"))]
const LOCALSTACK_ENDPOINT: &str = "LOCALSTACK_ENDPOINT";

/// A type to help tests that need a LocalStack instance.
#[cfg(any(test, feature = "test"))]
pub struct LocalStackTestContext {
    base_config: SdkConfig,
    endpoint: Endpoint,
    _guard: MutexGuard<'static, ()>,
}

#[cfg(any(test, feature = "test"))]
impl LocalStackTestContext {
    /// Creates an instance of [`LocalStackTestContext`], loading the necessary LocalStack
    /// configuration.
    ///
    /// An address to the LocalStack instance must be specified using a `LOCALSTACK_ENDPOINT`
    /// environment variable.
    ///
    /// This also locks the `LOCALSTACK_GUARD` to enforce that only one test has access to the
    /// LocalStack instance.
    pub async fn new() -> Result<LocalStackTestContext, Error> {
        let base_config = aws_config::load_from_env().await;
        let endpoint = Self::load_endpoint()?;
        let _guard = LOCALSTACK_GUARD.lock().await;

        let context = LocalStackTestContext {
            base_config,
            endpoint,
            _guard,
        };

        Ok(context)
    }

    /// Creates an [`Endpoint`] using the configuration in the [`LOCALSTACK_ENDPOINT`] environment
    /// variable.
    fn load_endpoint() -> Result<Endpoint, Error> {
        let endpoint_address = env::var(LOCALSTACK_ENDPOINT)
            .with_context(|| {
                format!(
                    "Missing LocalStack endpoint address in {LOCALSTACK_ENDPOINT:?} \
                    environment variable"
                )
            })?
            .parse()
            .context("LocalStack endpoint address is not a valid URI")?;

        Ok(Endpoint::immutable(endpoint_address))
    }

    /// Creates a new [`aws_sdk_dynamodb::Config`] for tests, using a LocalStack instance.
    pub fn dynamo_db_config(&self) -> aws_sdk_dynamodb::Config {
        aws_sdk_dynamodb::config::Builder::from(&self.base_config)
            .endpoint_resolver(self.endpoint.clone())
            .build()
    }
}

/// Creates the common initialization for RocksDB
#[cfg(any(test, feature = "test"))]
pub fn create_dynamo_db_common_config() -> CommonStoreConfig {
    CommonStoreConfig {
        max_concurrent_queries: Some(TEST_DYNAMO_DB_MAX_CONCURRENT_QUERIES),
        max_stream_queries: TEST_DYNAMO_DB_MAX_STREAM_QUERIES,
        cache_size: TEST_CACHE_SIZE,
    }
}

/// Creates a basic client that can be used for tests.
#[cfg(any(test, feature = "test"))]
pub async fn create_dynamo_db_test_client() -> DynamoDbClient {
    let common_config = create_dynamo_db_common_config();
    let table = get_table_name().await;
    let table_name = table.parse().expect("Invalid table name");
    let use_localstack = true;
    let config = get_config(use_localstack).await.expect("config");
    let store_config = DynamoDbKvStoreConfig {
        config,
        table_name,
        common_config,
    };
    let (key_value_operation, _) = DynamoDbClient::new_for_testing(store_config)
        .await
        .expect("key_value_operation");
    key_value_operation
}

/// Helper function to list the names of tables registered on DynamoDB.
pub async fn list_tables(
    client: &aws_sdk_dynamodb::Client,
) -> Result<Vec<String>, DynamoDbContextError> {
    Ok(client
        .list_tables()
        .send()
        .await?
        .table_names
        .expect("List of tables was not returned"))
}

/// Helper function to clear all the tables from the database
pub async fn clear_tables(client: &aws_sdk_dynamodb::Client) -> Result<(), DynamoDbContextError> {
    let tables = list_tables(client).await?;
    for table in tables {
        client.delete_table().table_name(&table).send().await?;
    }
    Ok(())
}
