searchState.loadedDescShard("rocksdb", 0, "Rust wrapper for RocksDB.\nUtility trait to accept both supported references to …\nAppends a compact hash table to the end of the data block …\nA space efficient index block that is optimized for …\nUse binary search when performing point lookup for keys in …\nUsed by BlockBasedOptions::set_index_type.\nFor configuring block-based file storage.\nA specialized opaque type used to represent a column …\nValue which can be converted into a C string.\nUsed by BlockBasedOptions::set_checksum_type.\nAn opaque type used to represent a column family. Returned …\nA descriptor for a RocksDB column family.\nHandy type alias to hide actual type difference to …\nConfiguration of cuckoo-based storage.\nA type alias to DB instance type with the single-threaded …\nMinimal set of DB-related methods, intended to be generic …\nA helper type to implement some common methods for …\nA type alias to keep compatibility. See …\nAn iterator over a database or column family, with …\nRepresents a path where sst files can be put into\nWrapper around RocksDB PinnableSlice struct.\nA type alias to keep compatibility. See …\nAn iterator over a database or column family, with …\nIterates the batches of writes since a given sequence …\nA type alias to RocksDB database.\nThe name of the default column family.\nUsed by BlockBasedOptions::set_data_block_index_type.\nAn Env is an interface used by the rocksdb implementation …\nA simple wrapper round a string, used for errors reported …\nRocksDB error kind.\nOptionally wait for the memtable flush to be performed.\nAlways compact bottommost level\nAlways compact bottommost level but in bottommost level …\nThe hash index, if enabled, will perform a hash lookup if …\nOnly compact bottommost level if there is a compaction …\nFor configuring external files ingestion.\nA range which can be set as iterate bounds on …\nThe metadata that describes a SST file\nDefines the underlying memtable implementation. See …\nActual marker type for the marker trait <code>ThreadMode</code>, which …\nA type alias to RocksDB Optimistic Transaction DB.\nDatabase-wide options around performance and behavior.\nUsed with DBOptions::set_plain_table_factory. See official …\nRepresentation of a range of keys starting with given …\nActual marker type for the marker trait <code>ThreadMode</code>, which …\nSkip bottommost level compaction\nA <code>SliceTransform</code> is a generic pluggable way of …\nA type alias to keep compatibility. See …\nA consistent view of the database at the point of creation.\nSstFileWriter is used to create sst files that can be …\nMarker trait to specify single or multi threaded column …\nRocksDB Transaction.\nRocksDB TransactionDB.\nA two-level index implementation. Both levels are binary …\nA type alias to keep compatibility. See …\nReceives the puts and deletes of a write batch.\nAn atomic batch of write operations.\nOptionally disable WAL or sync for this write.\nBakes self into value which can be freely converted into …\nReturn the values associated with the given keys and the …\nReturn the values associated with the given keys and the …\nRequest stopping background work, if wait is true wait …\nReturns the underlying column family handle\nReturns the underlying column family handle\nReturns the underlying column family handle.\nReturns the underlying column family handle.\nImplementation of bindings to RocksDB Checkpoint1 API\nClear all updates buffered in this batch.\nName of the column family the file belongs to\nWrite all batched keys to the DB atomically.\nRuns a manual compaction on the Range of keys given. This …\nRuns a manual compaction on the Range of keys given on the …\nSame as <code>compact_range_cf</code> but with custom options.\nSame as <code>compact_range</code> but with custom options.\nInitializes SstFileWriter with given DB options.\nCreates column family with given name and options\nCreates column family with given name and options\nCreates column family with given name and options.\nCreates column family with given name and options.\nIf true, the database will be created if it is missing.\nIf true, any column families that didn’t exist when …\nReturn a reference to a byte array which represents a …\nCalled with a key that was <code>delete</code>d from the batch.\nAdds a deletion key to currently opened file REQUIRES: key …\nDelete the key value if it exists and do conflict checking …\nRemoves the database entry for key. Does nothing if the …\nDelete the key value in the given column family and do …\nDelete sst files whose keys are entirely in the given …\nSame as <code>delete_file_in_range</code> but only for specific column …\nRemove database entries from start key to end key.\nRemoves the database entries in the range <code>[&quot;from&quot;, &quot;to&quot;)</code> …\nRemoves the database entries in the range <code>[&quot;from&quot;, &quot;to&quot;)</code> …\nRemove database entries in column family from start key to …\nRemoves the database entries in the range <code>[&quot;from&quot;, &quot;to&quot;)</code> …\nRemoves the database entries in the range <code>[&quot;from&quot;, &quot;to&quot;)</code> …\nDisable block cache\nSets whether WAL should be active or not. If true, writes …\nInternal implementation for dropping column family handles\nDrops the column family with the given name\nDrops the column family with the given name by internally …\nDrops the column family with the given name\nDrops the column family with the given name by internally …\nLargest user defined key in the file\nreturns the current file size\nSpecify whether the “data block”/“index block”/“…\nFinalize writing to sst file and close file.\nFlushes database memtables to SST files on the disk using …\nFlushes database memtables to SST files on the disk for a …\nFlushes database memtables to SST files on the disk for a …\nFlushes database memtables to SST files on the disk.\nFlushes the WAL buffer. If <code>sync</code> is set to <code>true</code>, also syncs …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nConstruct with a reference to a byte array serialized by …\nOpens an iterator with <code>set_total_order_seek</code> enabled. This …\nOpens an iterator with <code>set_total_order_seek</code> enabled. This …\nOpens an iterator with <code>set_total_order_seek</code> enabled. This …\nReturn the bytes associated with a key value. If you only …\nReturns the bytes associated with a key value with default …\nGet the bytes associated with a key value.\nReturns the bytes associated with a key value.\nReturn the bytes associated with a key value and the given …\nReturns the bytes associated with a key value and given …\nGet the bytes associated with a key value and the given …\nReturns the bytes associated with a key value and the …\nReturn the bytes associated with a key value and the given …\nReturns the bytes associated with a key value, given …\nGet the bytes associated with a key value and the given …\nReturns the bytes associated with a key value and the …\nGet the key and ensure that this transaction will only be …\nGet the key in the given column family and ensure that …\nGet the key in the given column family with read options …\nGet the key with read options and ensure that this …\nReturn the bytes associated with a key value with read …\nReturns the bytes associated with a key value and given …\nReturns the bytes associated with a key value with read …\nReturns the bytes associated with a key value with read …\nReturn the value associated with a key using RocksDB’s …\nReturn the value associated with a key using RocksDB’s …\nReturn the value associated with a key using RocksDB’s …\nReturn the value associated with a key using RocksDB’s …\nReturns the bytes associated with a key value and the …\nReturn the value associated with a key using RocksDB’s …\nReturn the value associated with a key using RocksDB’s …\nReturns the bytes associated with a key value and the …\nReturn the value associated with a key using RocksDB’s …\nReturn the value associated with a key using RocksDB’s …\nReturns the bytes associated with a key value with read …\nReturns the pinned memory usage in bytes.\nIterate over batches of write operations since a given …\nReturns the cache memory usage in bytes.\nBy default, RocksDB uses only one background thread for …\nLoads a list of external SST files created with …\nLoads a list of external SST files created with …\nLoads a list of external SST files created with …\nLoads a list of external SST files created with …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nConverts object into lower and upper bounds pair.\nConverts the prefix range representation into pair of …\nConsumers and converts value into an owned <code>CString</code>.\nReturns pair with slice of the current key and current …\nIterate the put and delete operations within this write …\nCreates an iterator over the data in this snapshot, using …\nCreates an iterator over the data in this snapshot under …\nOpens an iterator using the provided ReadOptions. This is …\nCreates an iterator over the data in this snapshot under …\nOpens an iterator using the provided ReadOptions. This is …\nOpens an iterator using the provided ReadOptions. This is …\nCreates an iterator over the data in this snapshot, using …\nWait for all threads started by StartThread to terminate.\nReturns a slice of the current key.\nReturns <code>false</code> if the given key definitely doesn’t exist …\nReturns <code>false</code> if the given key definitely doesn’t exist …\nReturns <code>false</code> if the given key definitely doesn’t exist …\nIf the key definitely does not exist in the database, then …\nReturns <code>false</code> if the given key definitely doesn’t exist …\nParse corresponding <code>ErrorKind</code> from error message.\nThe sequence number of the most recent transaction.\nLevel at which this file resides\nReturns a list of all table files with their level, start …\nConstructs the DBOptions and ColumnFamilyDescriptors by …\nLowering CPU priority for high priority thread pool.\nLowering IO priority for high priority thread pool.\nLowering CPU priority for threads from the specified pool.\nLowering IO priority for threads from the specified pool.\nReturns a new environment that stores its data in memory …\nAdds a Merge key with value to currently opened file …\nMerge value with existing value of key, and also do …\nMerge <code>value</code> with existing value of <code>key</code> in the given column …\nrustic merge operator\nReturn the values associated with the given keys.\nReturns the bytes associated with the given key values and …\nReturn the values associated with the given keys.\nReturn the values associated with the given keys.\nReturn the values associated with the given keys and …\nReturns the bytes associated with the given key values and …\nReturn the values associated with the given keys and …\nReturn the values associated with the given keys and …\nReturn the values associated with the given keys and …\nReturns the bytes associated with the given key values, …\nReturn the values associated with the given keys and …\nReturn the values associated with the given keys and …\nReturn the values associated with the given keys using …\nReturns the bytes associated with the given key values and …\nReturn the values associated with the given keys using …\nReturn the values associated with the given keys using …\nGet the name of the ColumnFamilyDescriptor.\nName of the file\nCreate a new path\nCreates a new <code>SnapshotWithThreadMode</code> of the database <code>db</code>.\nReturns default env\nInternal implementation for storing column family handles\nCreates a HyperClockCache with capacity in bytes.\nCreates an LRU cache with capacity in bytes.\nSeeks to the next key.\nNumber of deletions/tomb key(s) in the file\nNumber of entries/alive keys in the file\nOpens the database with the specified options.\nOpens the database with the specified options.\nOpens the database with the specified options.\nPrepare SstFileWriter to write into file located at “…\nOpens the database with the specified options.\nOpens the database with the specified options.\nOpens the database as a secondary.\nOpens the database as a secondary.\nOpens a database with the given database options and …\nOpens a database with the given database options and …\nOpens a database with the given database options and …\nOpens a database with the given database options and …\nOpens a database with the given database options and …\nOpens the database as a secondary with the given database …\nOpens the database as a secondary with the given database …\nOpens a database with the given database options and …\nOpens a database with the given database options and …\nOpens a database with the given database options and …\nOpens a database with the given database options and …\nOpens a database with the given database options and …\nOpens the database as a secondary with the given database …\nOpens the database as a secondary with the given database …\nOpens a database for ready only with the given database …\nOpens a database for ready only with the given database …\nOpens a database with the given database with a Time to …\nOpens a database with the given database with a Time to …\nOpens a database for read only with the given database …\nOpens a database for read only with the given database …\nOpens a database with the given database options and …\nOpens a database with the given database options and …\nOpens a database for read only with the given database …\nOpens a database for read only with the given database …\nOpens the database with a Time to Live compaction filter …\nOpens the database with a Time to Live compaction filter …\nOpens a database with default options.\nOpens a database with default options.\nOpens a database with default options.\nOpens a database with default options.\nOpens a database with default options.\nOpens the database for read only with the specified …\nOpens the database for read only with the specified …\nOpens the database with a Time to Live compaction filter.\nOpens the database with a Time to Live compaction filter.\nOptimize level style compaction.\nOptimize universal style compaction.\nPrepare the DB for bulk loading.\nGet all prepared transactions for recovery.\nSeeks to the previous key.\nProperties\nRetrieves a RocksDB property and casts it to an integer.\nRetrieves a RocksDB property for a specific column family …\nRetrieves a RocksDB property by name.\nRetrieves a RocksDB property by name, for a specific …\nCalled with a key and value that were <code>put</code> into the batch.\nAdds a Put key with value to currently opened file …\nPut the key value in default column family and do conflict …\nInsert a value into the database under the given key.\nPut the key value in the given column famuly and do …\nOpens a raw iterator over the database, using the default …\nCreates a raw iterator over the data in this snapshot, …\nOpens a raw iterator over the database, using the default …\nOpens a raw iterator over the database, using the default …\nOpens a raw iterator over the given column family, using …\nCreates a raw iterator over the data in this snapshot …\nOpens a raw iterator over the given column family, using …\nOpens a raw iterator over the given column family, using …\nOpens a raw iterator over the given column family, using …\nCreates a raw iterator over the data in this snapshot …\nOpens a raw iterator over the given column family, using …\nOpens a raw iterator over the given column family, using …\nOpens a raw iterator over the database, using the given …\nCreates a raw iterator over the data in this snapshot, …\nOpens a raw iterator over the database, using the given …\nOpens a raw iterator over the database, using the given …\nDiscard all batched writes in this transaction.\nUndo all operations in this transaction since the most …\nSeeks to the specified key or the first key that …\nSeeks to the specified key, or the first key that …\nSeeks to the first key in the database.\nSeeks to the last key in the database.\nSpecifies the file access pattern once a compaction is …\nWhen set to true, reading SST files will opt out of the …\nIf set to false and the file key range overlaps with the …\nIf true, allow multi-writers to update mem tables in …\nIf set to false, IngestExternalFile() will fail if the …\nAllow the OS to mmap file for reading sst tables.\nAllow the OS to mmap file for writing.\nHints to the OS that it should not buffer disk I/O. …\nSets the size of one block in arena memory allocation.\nAsynchronously prefetch some data.\nGuarantee that all column families are flushed together …\nIf true, when PurgeObsoleteFile is called in …\nSets the number of background worker threads of a specific …\nSets the blob compaction read ahead size.\nSets the blob compression type. All blob files use the same\nSets the size limit for blob files.\nSets the threshold that the GC logic uses to determine …\nSets the blob GC force threshold.\nSets global cache for blocks (user data is stored in a set …\nNumber of keys between restart points for delta encoding …\nApproximate size of user data packed per block. Note that …\nSets a Bloom filter policy to reduce disk reads.\nControl locality of bloom filter probes to improve cache …\nSets the size of the bottom priority thread pool that can …\nSets compression options for blocks at the bottom-most …\nSets the bottom-most compression algorithm that will be …\nSets bottommost level compaction.\nSets maximum size of training data passed to zstd’s …\nAllows OS to incrementally sync files to disk while they …\nIf cache_index_and_filter_blocks is enabled, cache index …\nSets cache capacity in bytes.\nIf true, compacted files will be moved to the minimum …\nUse the specified checksum type. Newly created table files …\nSets a compaction filter used to determine if entries …\nThis is a factory that provides compaction filter objects …\nIf non-zero, we perform bigger reads when doing …\nSets the compaction style.\nSets the comparator used to define the order of keys in …\nMaximum size of dictionaries used to prime the compression …\nDifferent levels can have different compression policies. …\nSets the percentage of compression size.\nSets the compression algorithm that will be used for …\nIn case of collision while inserting, the builder attempts …\nSets the table factory to a CuckooTableFactory (the …\nSet the data block hash index utilization ratio.\nSet the data block index type for point lookups: …\nSpecifies the absolute info LOG dir.\nA list of paths where SST files can be put into, with its …\nAmount of data to build up in memtables across all column …\nSpecifies whether detect deadlock or not.\nSpecifies the number of traversals to make during deadlock …\nSpecifies the wait timeout in milliseconds when writing a …\nSets the periodicity when obsolete files get deleted.\nDisables automatic compactions. Manual compactions can …\nIf true, then print malloc stats together with …\nEnable the use of key-value separation.\nIf this is set to true RocksDB will actively relocate …\nBy default, a single write thread queue is maintained. The …\nIf true, threads synchronizing with the write batch group …\nUse the specified object to interact with the environment, …\nSpecifies whether an error should be raised if the …\nIf more than one thread calls manual compaction, only one …\nSpecifies expiration duration in milliseconds.\nSets the options for FIFO compaction style.\nFormat version, reserved for backward compatibility.\nSets the bytes threshold at which all writes are stopped …\nDetermines the utilization of hash tables. Smaller values …\nSets the size of the high priority thread pool that can be …\nSets a hybrid Ribbon filter policy to reduce disk reads.\nIf this option is enabled, user key is treated as uint64_t …\nIf true and if user is trying to write to column families …\nIf true, keys deleted using the DeleteRange() API will be …\nSame as block_restart_interval but used for the index …\nDefines the index type to be used for SS-table lookups.\nSet to true if you would like duplicate keys in the file …\nSets the number of locks used for inplace update.\nEnable/disable thread-safe inplace updates.\nEnable/dsiable child process inherit open files.\nSets the lower bound for an iterator.\nSets lower and upper bounds based on the provided range.  …\nSets the upper bound for an iterator. The upper bound …\nSpecify the maximal number of info log files to be kept.\nAllow RocksDB to pick dynamic base of bytes for levels. …\nSets the number of files to trigger level-0 compaction. A …\nSets the soft limit on number of level-0 files. We start …\nSets the maximum number of level-0 files.  We stop writes …\nSpecifies the wait timeout in milliseconds when a …\nSets the time for the info log file to roll (in seconds).\nSpecifies the log level. Consider the <code>LogLevel</code> enum for a …\nIf true, this write request is of lower priority if …\nSets the size of the low priority thread pool that can be …\nSets the number of bytes to preallocate (via fallocate) …\nIf enabled, WAL is not flushed automatically after each …\nSets the maximum number of concurrent background …\nSets the maximum number of concurrent background memtable …\nSets maximum number of concurrent background jobs …\nControl maximum total data size for a level. …\nDefault: <code>10</code>\nDifferent max-size multipliers for different levels. These …\nSets the maximum number of bytes in all compacted files. …\nIf max_open_files is -1, DB will open all files on …\nSets the maximal size of the info log file.\nThe manifest file is rolled over on reaching this limit. …\nSets the maximum number of files in a single compaction …\nSpecifies the maximum number of keys that can be locked at …\nSets the number of open files that can be used by the DB. …\nA property used by builder to determine the depth to go to …\nSpecifies whether an iteration-&gt;Next() sequentially skips …\nsets the size amplification.\nSets a threshold for the number of keys that can be skipped\nSets maximum number of threads that will concurrently …\nSets the maximum number of successive merge operations on …\nSets the max table file size.\nOnce write-ahead logs exceed this size, we will start …\nSpecifies the maximum number of bytes used for the write …\nSets the maximum number of write buffers that are built up …\nThe total maximum size(bytes) of write buffers to maintain …\nDefines the underlying memtable implementation. See …\nSetMemtableHugePageSize sets the page size for huge page …\nIf true, writebatch will maintain the last insert …\nWhen a <code>prefix_extractor</code> is defined through …\nEnable whole key bloom filter in memtable. Note this will …\nBlock size for partitioned metadata. Currently applied to …\nSets the minimum threshold value at or above which will be …\nSets the start level to use compression.\nSets the minimum number of files in a single compaction …\nSets the minimum number of write buffers that will be …\nSets the minimum number of write buffers that will be …\nCan be set to true to move the files instead of copying …\nIf true and we need to wait or sleep for the write …\nSets the number of levels for this database.\nSpecifies lock table stripes count.\nSets the optimize_filters_for_hits flag\nEnable/disable paranoid checks.\nNote: currently this option requires kTwoLevelIndexSearch …\nSpecifies the value of “pin_data”. If true, it keeps …\nIf cache_index_and_filter_blocks is true and the below is …\nIf cache_index_and_filter_blocks is true and the below is …\nSets the factory as plain table. See official wiki for more\nEnforce that the iterator only iterates over the same …\nUse to control write rate of flush and compaction. Flush …\nSpecify if this read request should process data that …\nIf non-zero, an iterator will create a new table reader …\nControls the recycling of log files.\nMeasure IO stats in compactions and flushes, if <code>true</code>.\nSets a Ribbon filter policy to reduce disk reads.\nSets global cache for table-level rows. Cache must outlive …\nRecord the state of the transaction for future calls to …\nSets the percentage flexibility while comparing file size. …\nIf true, then DB::Open() will not fetch and check sizes of …\nIf true, then DB::Open() will not update the statistics …\nSets the snapshot which should be used for the read. The …\nSpecifies use snapshot or not.\nSpecifies use snapshot or not.\nIf set to false, an ingested file keys could appear in …\nSets the threshold at which all writes will be slowed down …\nIf not zero, dump <code>rocksdb.stats</code> to LOG every …\nIf not zero, dump rocksdb.stats to RocksDB to LOG every …\nSets the algorithm used to stop picking files into a …\nSets the sync mode. If true, the write will be flushed …\nSets the number of shards used for table cache.\nIf true, create a tailing iterator. Note that tailing …\nSets the target file size for compaction. …\nBy default target_file_size_multiplier is 1, which means …\nIf change_level is true and target_level have non-negative …\nEnable a total order seek regardless of index format (e.g. …\nSpecifies the default wait timeout in milliseconds when a …\nSets the options needed to support Universal Style …\nSets unordered_write to true trades higher write …\nEnable/disable adaptive mutex, which spins in the user …\nEnable direct I/O mode for flush and compaction\nEnable direct I/O mode for reading they may or may not …\nBy default, writes to stable storage use fdatasync (on …\nIf this option is set to true, module is used during hash …\nIf true, all data read from underlying storage will be …\nWaits until the flush is done.\nSame as bytes_per_sync, but applies to WAL files.\nSpecifies the absolute path of the directory the …\nRecovery mode to control the consistency while replaying …\nSets the WAL size limit in MB.\nSets the WAL ttl in seconds.\nIf false, place only prefixes in the filter, not whole …\nSets the maximum buffer size that is used by …\nSets the amount of data to build up in memory (backed by …\nSets maximum size of training data passed to zstd’s …\nSize of the file\nReturn WriteBatch serialized size (in bytes).\nReturns snapshot associated with transaction if snapshot …\nSmallest user defined key in the file\nReturns an error <code>Result</code> if the iterator has encountered an …\nReturns an error <code>Result</code> if the iterator has encountered an …\nCreates a transaction with default options.\nCreates a transaction with default options.\nCreates a transaction with default options.\nCreates a transaction with default options.\nCreates a transaction with default options.\nCreates a transaction with options.\nTries to catch up with the primary by reading as much as …\nReturns <code>true</code> if the iterator is valid. An iterator is …\nReturns <code>true</code> if the iterator is valid. An iterator is …\nReturns a slice of the current value.\nRepresents information of a backup including timestamp of …\nID of the backup\nCaptures the state of the database in the latest backup.\nCaptures the state of the database in the latest backup.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet a list of all backups together with information on …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nInitializes <code>BackupEngineOptions</code> with the directory to be …\nNumber of files related to the backup\nOpen a backup engine with the specified options and …\nRestore from a specified backup\nRestore from the latest backup\nSets <code>keep_log_files</code>. If true, restore won’t overwrite …\nSets the number of operations (such as file copies or file …\nSize of the backup\nTimestamp of the backup\nChecks that each file exists and that the size of the file …\nDatabase’s checkpoint object. Used to create checkpoints …\nCreates new physical DB checkpoint in directory specified …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCreates new checkpoint object for specific DB.\nChange the value for the key\nCompactionFilter allows an application to modify/delete a …\nFunction to filter compaction with.\nDecision about how to handle compacting an object\nKeep the old value\nRemove the object from the database\nThe compaction process invokes this method for kv that is …\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns a name that identifies this compaction filter. The …\nContext information of a compaction run\nEach compaction will create a new CompactionFilter …\nReturns a CompactionFilter for the compaction process\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nDoes this compaction run include all data files\nIs this compaction requested by the client (true), or is …\nReturns a name that identifies this compaction filter …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nDisable perf stats\nEnables only count stats\nEnables count and time stats\nOther than time, also measure CPU time counters. Still don…\nCount stats and enable time stats except for mutexes\nMemory usage stats\nN.B must always be the last value!\nThread local context for gathering performance counter …\nUnknown settings\nApproximate memory usage by cache\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet memory usage stats from DB instances and Cache …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nApproximate memory usage of all the table readers\nApproximate memory usage of all the mem-tables\nApproximate memory usage of un-flushed mem-tables\nReturns value of a metric\nGet the report on perf\nReset context\nSets the perf stats level for current thread.\n“rocksdb.actual-delayed-write-rate” - returns the …\n“rocksdb.aggregated-table-properties” - returns a …\n“rocksdb.background-errors” - returns accumulated …\n“rocksdb.base-level” - returns number of level to …\n“rocksdb.block-cache-capacity” - returns block cache …\n“rocksdb.block-cache-pinned-usage” - returns the …\n“rocksdb.block-cache-usage” - returns the memory size …\n“rocksdb.cfstats” - Both of “…\n“rocksdb.cfstats-no-file-histogram” - returns a …\n“rocksdb.cf-file-histogram” - print out how many file …\n“rocksdb.compaction-pending” - returns 1 if at least …\n“rocksdb.current-super-version-number” - returns …\n“rocksdb.cur-size-active-mem-table” - returns …\n“rocksdb.cur-size-all-mem-tables” - returns …\n“rocksdb.dbstats” - returns a multi-line string with …\n“rocksdb.estimate-live-data-size” - returns an …\n“rocksdb.estimate-num-keys” - returns estimated number …\n“rocksdb.estimate-oldest-key-time” - returns an …\n“rocksdb.estimate-pending-compaction-bytes” - returns …\n“rocksdb.estimate-table-readers-mem” - returns …\n“rocksdb.is-file-deletions-enabled” - returns 0 if …\n“rocksdb.is-write-stopped” - Return 1 if write has …\n“rocksdb.levelstats” - returns multi-line string …\n“rocksdb.live-sst-files-size” - returns total size …\n“rocksdb.mem-table-flush-pending” - returns 1 if a …\n“rocksdb.min-log-number-to-keep” - return the minimum …\n“rocksdb.min-obsolete-sst-number-to-keep” - return the …\n“rocksdb.num-deletes-active-mem-table” - returns total …\n“rocksdb.num-deletes-imm-mem-tables” - returns total …\n“rocksdb.num-entries-active-mem-table” - returns total …\n“rocksdb.num-entries-imm-mem-tables” - returns total …\n“rocksdb.num-immutable-mem-table” - returns number of …\n“rocksdb.num-immutable-mem-table-flushed” - returns …\n“rocksdb.num-live-versions” - returns number of live …\n“rocksdb.num-running-compactions” - returns the number …\n“rocksdb.num-running-flushes” - returns the number of …\n“rocksdb.num-snapshots” - returns number of unreleased …\n“rocksdb.oldest-snapshot-time” - returns number …\n“rocksdb.options-statistics” - returns multi-line …\n“rocksdb.size-all-mem-tables” - returns approximate …\n“rocksdb.sstables” - returns a multi-line string …\n“rocksdb.stats” - returns a multi-line string …\n“rocksdb.total-sst-files-size” - returns total size …\n“rocksdb.aggregated-table-properties-at-level”, same …\n“rocksdb.compression-ratio-at-level” - returns string …\n“rocksdb.num-files-at-level” - returns string …")